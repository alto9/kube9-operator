# kube9-operator

**Kubernetes Operator for the kube9 VS Code Extension**

The kube9-operator runs in your Kubernetes cluster to enable enhanced features in the [kube9 VS Code extension](https://github.com/alto9/kube9-vscode). It provides tier detection, status reporting, and optional Pro tier features with AI-powered insights.

![Node.js](https://img.shields.io/badge/Node.js-22+-green) ![Kubernetes](https://img.shields.io/badge/Kubernetes-1.24+-blue) ![License](https://img.shields.io/badge/License-MIT-blue)

## Overview

The kube9-operator bridges your Kubernetes cluster with the kube9 VS Code extension, enabling the extension to determine whether your cluster is in:

- **Basic mode** (no operator) - kubectl-only operations
- **Free tier** (operated mode) - Local webviews and basic resource management
- **Pro tier** (enabled mode) - AI-powered insights, advanced dashboards, and rich UIs

The operator is installed via Helm and requires no ingress - all communication is outbound to kube9-server for Pro tier features.

## Features

### Free Tier (No API Key)
âœ… Status exposure via ConfigMap  
âœ… Cluster tier detection for VS Code extension  
âœ… Health monitoring  
âœ… Minimal resource footprint (~100m CPU, 128Mi RAM)  
âœ… No external communication

### Pro Tier (With API Key)
âœ¨ All Free tier features  
âœ¨ Registration with kube9-server  
âœ¨ API key validation  
âœ¨ Enables AI-powered features in VS Code extension  
âœ¨ Enhanced dashboards and insights  
âœ¨ Advanced cluster analytics

### ArgoCD Awareness
ğŸ” Automatic ArgoCD detection  
ğŸ” Configurable detection behavior  
ğŸ” Status exposed via OperatorStatus ConfigMap  
ğŸ” Foundation for future GitOps integration

The operator automatically detects if ArgoCD is installed in your cluster and exposes this information through the OperatorStatus. This enables the VS Code extension to conditionally show ArgoCD-related features and provides the foundation for future ArgoCD integration and AI-powered GitOps insights.

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  VS Code Extension                  â”‚
â”‚  - Reads operator status            â”‚
â”‚  - Enables features based on tier   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚ reads
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Kubernetes Cluster                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ kube9-system namespace        â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚  â”‚ kube9-operator          â”‚  â”‚  â”‚
â”‚  â”‚  â”‚ - Mode: operated/enabledâ”‚  â”‚  â”‚
â”‚  â”‚  â”‚ - Writes status         â”‚  â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚  â”‚ Status ConfigMap        â”‚  â”‚  â”‚
â”‚  â”‚  â”‚ - tier: free/pro        â”‚  â”‚  â”‚
â”‚  â”‚  â”‚ - health: healthy       â”‚  â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚ (Pro tier only)
              â†“ registers
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  kube9-server (api.kube9.dev)       â”‚
â”‚  - Validates API keys               â”‚
â”‚  - Enables Pro features             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Quick Start

### Prerequisites

- Kubernetes cluster (1.24+)
- `kubectl` configured with cluster access
- `helm` 3.x installed

### Install Free Tier

```bash
# Add Helm repository
helm repo add kube9 https://charts.kube9.dev
helm repo update

# Install operator (no API key = free tier)
helm install kube9-operator kube9/kube9-operator \
  --namespace kube9-system \
  --create-namespace
```

### Install Pro Tier

1. **Get your API key** from [portal.kube9.dev](https://portal.kube9.dev)

2. **Install with API key:**
```bash
helm install kube9-operator kube9/kube9-operator \
  --set apiKey=kdy_prod_YOUR_KEY_HERE \
  --namespace kube9-system \
  --create-namespace
```

### Verify Installation

```bash
# Check operator pod
kubectl get pods -n kube9-system

# View operator logs
kubectl logs -n kube9-system deployment/kube9-operator

# Check status ConfigMap
kubectl get configmap kube9-operator-status -n kube9-system -o yaml
```

## Configuration

### Helm Values

| Parameter | Description | Default |
|-----------|-------------|---------|
| `apiKey` | Optional API key for Pro tier | `""` |
| `image.repository` | Operator image repository | `ghcr.io/alto9/kube9-operator` |
| `image.tag` | Operator image tag | `1.0.0` |
| `resources.requests.cpu` | CPU request | `100m` |
| `resources.requests.memory` | Memory request | `128Mi` |
| `resources.limits.cpu` | CPU limit | `200m` |
| `resources.limits.memory` | Memory limit | `256Mi` |
| `logLevel` | Log level (debug, info, warn, error) | `info` |
| `statusUpdateIntervalSeconds` | Status update frequency | `60` |
| `serverUrl` | kube9-server URL (Pro tier) | `https://api.kube9.dev` |
| `argocd.autoDetect` | Enable automatic ArgoCD detection | `true` |
| `argocd.enabled` | Explicitly enable or disable ArgoCD integration (optional override) | - |
| `argocd.namespace` | Custom namespace where ArgoCD is installed | `"argocd"` |
| `argocd.selector` | Custom label selector for ArgoCD server deployment | `"app.kubernetes.io/name=argocd-server"` |
| `argocd.detectionInterval` | Detection check interval in hours | `6` |

### Custom Configuration

Create a `values.yaml`:

```yaml
apiKey: kdy_prod_YOUR_KEY_HERE

resources:
  requests:
    memory: "256Mi"
    cpu: "200m"
  limits:
    memory: "512Mi"
    cpu: "400m"

logLevel: debug

statusUpdateIntervalSeconds: 30
```

Install with custom values:

```bash
helm install kube9-operator kube9/kube9-operator \
  --namespace kube9-system \
  --create-namespace \
  --values values.yaml
```

### ArgoCD Configuration Examples

**Default auto-detection** (recommended):
```yaml
argocd:
  autoDetect: true
```

**Custom namespace**:
```yaml
argocd:
  autoDetect: true
  namespace: "gitops"  # ArgoCD installed in custom namespace
```

**Explicitly enable ArgoCD integration**:
```yaml
argocd:
  enabled: true  # Bypasses CRD check, directly checks namespace
  namespace: "argocd"
```

**Disable ArgoCD detection**:
```yaml
argocd:
  autoDetect: false  # Disables automatic detection
```

**Custom detection interval**:
```yaml
argocd:
  autoDetect: true
  detectionInterval: 12  # Check every 12 hours instead of default 6 hours
```

## Upgrading

### Add API Key (Free â†’ Pro)

```bash
helm upgrade kube9-operator kube9/kube9-operator \
  --namespace kube9-system \
  --set apiKey=kdy_prod_YOUR_KEY_HERE \
  --reuse-values
```

### Update to New Version

```bash
helm repo update
helm upgrade kube9-operator kube9/kube9-operator \
  --namespace kube9-system
```

## Uninstalling

```bash
helm uninstall kube9-operator --namespace kube9-system
```

## Development

### Prerequisites

- Node.js 22+
- kubectl with cluster access
- Docker (for building images)
- minikube (for local testing)

### Local Development with Minikube

The recommended workflow for developing kube9-operator is to run it locally connected to a minikube cluster. This provides the fastest iteration cycle without Docker rebuilds.

#### Quick Start

```bash
# Step 1: Ensure minikube is running (run this helper script)
./scripts/dev-minikube.sh

# Step 2: Run operator locally (connects to minikube via kubeconfig)
npm run dev:watch  # For auto-reload on file changes
# Or: npm run dev   # For single run
```

**Important:** 
- minikube must be started separately before running the operator. The `dev-minikube.sh` script will start it if it's not running.
- Environment variables are set with defaults in the npm scripts. To override, set them in your shell or create a `.env` file (see `.env.example`).

The operator will:
- Run on your local machine (not in a pod)
- Connect to minikube via kubeconfig (from `~/.kube/config`)
- Auto-reload on code changes (with `dev:watch` via nodemon)
- Create/update ConfigMaps in the minikube cluster

#### Prerequisites for Local Development

1. **Install minikube**: https://minikube.sigs.k8s.io/docs/start/
2. **Start minikube**: `minikube start` (or use `./scripts/dev-minikube.sh`)
3. **Verify kubectl context**: `kubectl config current-context` should show "minikube"
4. **Environment variables**: Defaults are set in npm scripts. To customize, set `SERVER_URL` and other vars in your shell or create a `.env` file (see `.env.example`)

#### Environment Variables

The operator requires `SERVER_URL` to be set. The npm scripts provide defaults, but you can override:

```bash
# Set in your shell
export SERVER_URL=https://api.kube9.dev
export LOG_LEVEL=debug

# Or create a .env file (see .env.example)
cp .env.example .env
# Edit .env with your values
```

#### Development Workflow

**Local Development (Recommended for daily work):**
```bash
# Step 1: Ensure minikube is running
./scripts/dev-minikube.sh  # Starts minikube if not running

# Step 2: Run operator locally with auto-reload
npm run dev:watch

# Edit code â†’ changes auto-reload â†’ test immediately
```

**Note:** `npm run dev` runs once (no auto-reload). Use `npm run dev:watch` for development with auto-reload.

**In-Cluster Testing (Recommended before PR):**
```bash
# Build Docker image, load into minikube, and deploy
npm run deploy:minikube

# Verify deployment
kubectl get pods -n kube9-system
kubectl logs -n kube9-system deployment/kube9-operator
```

#### Available npm Scripts

| Script | Description |
|--------|-------------|
| `npm run dev` | Run operator locally once (connects to minikube) |
| `npm run dev:watch` | Run operator locally with auto-reload on file changes |
| `npm run docker:build` | Build Docker image locally |
| `npm run docker:load:minikube` | Build and load image into minikube |
| `npm run deploy:minikube` | Build, load, and deploy operator to minikube |
| `npm run clean:minikube` | Uninstall operator from minikube |

#### Helper Scripts

- **`scripts/dev-minikube.sh`**: Checks minikube setup and provides development commands
- **`scripts/deploy-minikube.sh`**: Builds image, loads into minikube, and deploys with Helm

#### Troubleshooting

**Operator can't connect to minikube:**
```bash
# Verify minikube is running
minikube status

# Verify kubectl context
kubectl config current-context  # Should be "minikube"
kubectl config use-context minikube  # If not set
```

**Image not found when deploying:**
```bash
# Ensure image is loaded into minikube
minikube image ls | grep kube9-operator

# Reload image if needed
npm run docker:load:minikube
```

**RBAC permission errors:**
```bash
# For local development, ensure you have cluster-admin permissions
kubectl auth can-i create configmaps --namespace=kube9-system
```

For more detailed troubleshooting and best practices, see:
- **Developer Actor**: [`ai/actors/users/kube9-operator-developer.actor.md`](ai/actors/users/kube9-operator-developer.actor.md)
- **Development Context**: [`ai/contexts/development/minikube-local-development.context.md`](ai/contexts/development/minikube-local-development.context.md)

### Build Docker Image

```bash
npm run docker:build
# Or manually:
docker build -t kube9-operator:local .
```

### Run Tests

```bash
# Unit tests
npm test

# Integration tests (requires minikube cluster)
npm run test:minikube
```

### Helm Chart Development

```bash
# Lint Helm chart
helm lint charts/kube9-operator

# Test template rendering
helm template kube9-operator charts/kube9-operator \
  --namespace kube9-system \
  --set apiKey=test123

# Test installation in minikube
npm run deploy:minikube
npm run clean:minikube
```

## How It Works

### Status Exposure

The operator writes its status to a ConfigMap every 60 seconds:

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: kube9-operator-status
  namespace: kube9-system
data:
  status: |
    {
      "mode": "enabled",
      "tier": "pro",
      "version": "1.0.0",
      "health": "healthy",
      "lastUpdate": "2025-11-10T15:30:00Z",
      "registered": true,
      "error": null,
      "argocd": {
        "detected": true,
        "namespace": "argocd",
        "version": "v2.8.0",
        "lastChecked": "2025-11-10T15:30:00Z"
      }
    }
```

The VS Code extension reads this ConfigMap to:
- Determine which features to enable
- Show appropriate UI (local vs rich web UIs)
- Display cluster status to the user

### Tier Modes

| Mode | API Key | Registered | Extension Behavior |
|------|---------|------------|--------------------|
| **basic** | No operator | - | kubectl-only operations, show installation prompts |
| **operated** | Installed, no key | No | Local webviews, basic features, show upgrade prompts |
| **enabled** | Installed, has key | Yes | Rich UIs from server, AI features, advanced dashboards |
| **degraded** | Installed, has key | No | Temporary fallback, registration failed |

### Security

- **No Ingress Required**: Operator only makes outbound HTTPS connections
- **API Key Storage**: Stored in Kubernetes Secrets, never logged
- **Minimal Permissions**: ClusterRole for read-only cluster metadata, Role for ConfigMap writes
- **Non-Root**: Runs as non-root user with read-only filesystem
- **No Sensitive Data**: Status exposes no credentials or sensitive cluster information

## Troubleshooting

### Operator pod not starting

```bash
# Check pod status
kubectl get pods -n kube9-system

# View pod events
kubectl describe pod -n kube9-system -l app.kubernetes.io/name=kube9-operator

# Check logs
kubectl logs -n kube9-system deployment/kube9-operator
```

### Status ConfigMap not created

```bash
# Check RBAC permissions
kubectl auth can-i create configmaps --namespace=kube9-system --as=system:serviceaccount:kube9-system:kube9-operator

# Verify Role and RoleBinding exist
kubectl get role,rolebinding -n kube9-system
```

### Pro tier not working

```bash
# Verify API key Secret exists
kubectl get secret kube9-operator-config -n kube9-system

# Check registration status in logs
kubectl logs -n kube9-system deployment/kube9-operator | grep -i registration

# View status with error details
kubectl get configmap kube9-operator-status -n kube9-system -o jsonpath='{.data.status}' | jq .
```

### ArgoCD detection issues

**ArgoCD not detected when it should be:**

```bash
# Check operator logs for detection errors
kubectl logs -n kube9-system deployment/kube9-operator | grep -i argocd

# Verify ArgoCD namespace configuration matches your installation
kubectl get namespace argocd  # or your custom namespace

# Check if ArgoCD server deployment exists
kubectl get deployment -n argocd -l app.kubernetes.io/name=argocd-server

# Verify Helm values configuration
helm get values kube9-operator -n kube9-system | grep argocd
```

**Permission errors (RBAC):**

ArgoCD detection requires read-only permissions for:
- CustomResourceDefinitions (to check for `applications.argoproj.io` CRD)
- Namespaces (to verify ArgoCD namespace exists)
- Deployments (to find ArgoCD server deployment)

These permissions are automatically included in the ClusterRole when `rbac.create: true` (default). To verify permissions:

```bash
# Check if operator can read CRDs
kubectl auth can-i get customresourcedefinitions --namespace=kube9-system --as=system:serviceaccount:kube9-system:kube9-operator

# Check if operator can read namespaces
kubectl auth can-i get namespaces --namespace=kube9-system --as=system:serviceaccount:kube9-system:kube9-operator

# Check if operator can list deployments
kubectl auth can-i list deployments --namespace=argocd --as=system:serviceaccount:kube9-system:kube9-operator
```

If permissions are missing, ensure `rbac.create: true` in your Helm values or manually add the required permissions to your ClusterRole.

**How to check detection status:**

```bash
# View ArgoCD status from ConfigMap
kubectl get configmap kube9-operator-status -n kube9-system -o jsonpath='{.data.status}' | jq '.argocd'
```

The `argocd` field contains:
- `detected`: `true` if ArgoCD is detected, `false` otherwise
- `namespace`: Namespace where ArgoCD was detected (or `null` if not detected)
- `version`: ArgoCD version extracted from deployment (or `null` if unavailable)
- `lastChecked`: ISO 8601 timestamp of the last detection check

Example output when ArgoCD is detected:
```json
{
  "detected": true,
  "namespace": "argocd",
  "version": "v2.8.0",
  "lastChecked": "2025-11-20T15:30:00Z"
}
```

Example output when ArgoCD is not detected:
```json
{
  "detected": false,
  "namespace": null,
  "version": null,
  "lastChecked": "2025-11-20T15:30:00Z"
}
```

## Project Structure

```
kube9-operator/
â”œâ”€â”€ ai/                          # Forge design documentation
â”‚   â”œâ”€â”€ actors/                  # System and user actors
â”‚   â”œâ”€â”€ contexts/                # Implementation guidance
â”‚   â”œâ”€â”€ diagrams/                # Architecture diagrams
â”‚   â”œâ”€â”€ features/                # Feature definitions (Gherkin)
â”‚   â”œâ”€â”€ models/                  # Data models
â”‚   â”œâ”€â”€ sessions/                # Design sessions
â”‚   â”‚   â””â”€â”€ mvp/                 # MVP session
â”‚   â”‚       â”œâ”€â”€ tickets/         # Implementation stories
â”‚   â”‚       â””â”€â”€ mvp.session.md
â”‚   â””â”€â”€ specs/                   # Technical specifications
â”œâ”€â”€ charts/                      # Helm chart
â”‚   â””â”€â”€ kube9-operator/
â”‚       â”œâ”€â”€ Chart.yaml
â”‚       â”œâ”€â”€ values.yaml
â”‚       â””â”€â”€ templates/
â”œâ”€â”€ src/                         # TypeScript source code
â”‚   â”œâ”€â”€ cluster/                 # Cluster identifier
â”‚   â”œâ”€â”€ config/                  # Configuration loader
â”‚   â”œâ”€â”€ health/                  # Health endpoints
â”‚   â”œâ”€â”€ kubernetes/              # Kubernetes client
â”‚   â”œâ”€â”€ logging/                 # Structured logging
â”‚   â”œâ”€â”€ registration/            # Server registration
â”‚   â”œâ”€â”€ shutdown/                # Graceful shutdown
â”‚   â””â”€â”€ status/                  # Status calculator & writer
â”œâ”€â”€ tests/                       # Tests
â”‚   â”œâ”€â”€ integration/             # Integration tests
â”‚   â””â”€â”€ unit/                    # Unit tests
â”œâ”€â”€ Dockerfile                   # Production container image
â”œâ”€â”€ package.json                 # Node.js dependencies
â””â”€â”€ tsconfig.json                # TypeScript configuration
```

## Related Projects

- **[kube9-vscode](https://github.com/alto9/kube9-vscode)** - VS Code extension (primary consumer)
- **[kube9-server](https://github.com/alto9/kube9-server)** - Backend server for Pro features
- **[kube9-portal](https://github.com/alto9/kube9-portal)** - User portal for account management

## Documentation

- **[Design Documentation](./ai/docs/mvp-overview.md)** - Complete MVP design and architecture
- **[Implementation Stories](./ai/sessions/mvp/tickets/)** - Breakdown of implementation work
- **[API Specifications](./ai/specs/)** - Technical API specs
- **[Feature Definitions](./ai/features/)** - Feature behavior in Gherkin

## Contributing

We welcome contributions! Please see our [Contributing Guide](CONTRIBUTING.md) for details on:

- How to set up your development environment
- Local development with minikube
- Our code style and conventions
- How to submit pull requests
- Testing and deployment

This project uses [Forge](https://github.com/alto9/forge) for structured context engineering:

1. Review design docs in `ai/` folder
2. Check implementation stories in `ai/sessions/mvp/tickets/`
3. Follow specs and contexts for implementation guidance
4. Update story status as work progresses

### Quick Start for Contributors

```bash
# Fork and clone
git clone https://github.com/alto9/kube9-operator.git
cd kube9-operator

# Install dependencies
npm install

# Start minikube
./scripts/dev-minikube.sh

# Run operator locally with auto-reload
npm run dev:watch
```

## License

MIT License - see [LICENSE](LICENSE) file for details

## Support

- **Documentation**: https://docs.kube9.dev
- **GitHub Issues**: https://github.com/alto9/kube9-operator/issues - Report bugs, request features
- **GitHub Discussions**: https://github.com/alto9/kube9-operator/discussions - Ask questions, share ideas
- **Contributing Guide**: [CONTRIBUTING.md](CONTRIBUTING.md) - How to contribute
- **Security Policy**: [SECURITY.md](SECURITY.md) - Security reporting
- **Code of Conduct**: [CODE_OF_CONDUCT.md](CODE_OF_CONDUCT.md) - Community guidelines
- **Portal Support**: https://portal.kube9.dev/support

---

**Built with â¤ï¸ by Alto9 - Making Kubernetes management intelligent**
